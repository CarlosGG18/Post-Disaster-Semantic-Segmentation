{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "tEXeH0t5jkzM"
      },
      "outputs": [],
      "source": [
        "import h5py\n",
        "import numpy as np \n",
        "import matplotlib.pyplot as plt \n",
        "import matplotlib.image as mpimg\n",
        "import matplotlib.patches as mpatches\n",
        "import tensorflow\n",
        "import keras\n",
        "import os\n",
        "import cv2\n",
        "from PIL import Image\n",
        "keras.utils.generic_utils = keras.utils\n",
        "from keras.optimizers import SGD, Adam\n",
        "import random\n",
        "from keras.models import Sequential, Model, load_model\n",
        "# from keras.layers import Dense, Dropout, Activation, Flatten,Reshape,Input\n",
        "# from keras.layers import Conv2D, MaxPooling2D, UpSampling2D,concatenate\n",
        "# from keras.layers.convolutional.conv2d_transpose import Conv2DTranspose\n",
        "import matplotlib"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "iOe9c4M43Zfz"
      },
      "outputs": [],
      "source": [
        "patch_size=256\n",
        "img_height = 3000\n",
        "img_width = 4000\n",
        "n_classes= 10\n",
        "train_grid_size = 256\n",
        "height = train_grid_size\n",
        "width = train_grid_size\n",
        "resize_dim = (2*train_grid_size, 2*train_grid_size)\n",
        "h_n = int(resize_dim[0]/height)\n",
        "w_n = int(resize_dim[0]/width)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "yulL2cy_1o5K",
        "outputId": "0f03a965-37d4-48cc-ee6b-94708fe06715"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "wd = os.getcwd()\n",
        "wd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "xU47jQ6_2Imh"
      },
      "outputs": [],
      "source": [
        "training_img_path= wd + '/drive/MyDrive/Floodnet/train/train-org-img'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "eUidBoM24l6v"
      },
      "outputs": [],
      "source": [
        "images= os.listdir(training_img_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "GoV2R7Ne01Gy"
      },
      "outputs": [],
      "source": [
        "train_floodnet_images =[]\n",
        "for img_path in images:\n",
        "  img = cv2.imread(\"/\".join((training_img_path, img_path)),1)\n",
        "  img = img[0:img_height, 0:img_width,:]\n",
        "  img = cv2.resize(img, resize_dim)\n",
        "  i = 0\n",
        "  j = 0\n",
        "  y = 0\n",
        "\n",
        "  for i in range(h_n):\n",
        "        x=0\n",
        "        for j in range(w_n):\n",
        "            img_crop = img[y:(y+height), x:(x+width), :]\n",
        "            train_floodnet_images.append(img_crop)\n",
        "            x+=width\n",
        "        y+=height\n",
        "train_floodnet_images = np.array(train_floodnet_images)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "MOzYmJwr2GC6"
      },
      "outputs": [],
      "source": [
        "training_mask_path =os.getcwd() + '/drive/MyDrive/Floodnet/train/train-label-img'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "_MG6ET-q42H_"
      },
      "outputs": [],
      "source": [
        "train_masks= os.listdir(training_mask_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "4PMacyQT5D-c"
      },
      "outputs": [],
      "source": [
        "train_flooded_mask=[]\n",
        "for mask_path in train_masks:\n",
        "  mask = cv2.imread(\"/\".join((training_mask_path, mask_path)),0)\n",
        "  mask = mask[0:img_height, 0:img_width]\n",
        "  mask = cv2.resize(mask, resize_dim)\n",
        "  i = 0\n",
        "  j = 0\n",
        "  y = 0\n",
        "\n",
        "  for i in range(h_n):\n",
        "        x=0\n",
        "        for j in range(w_n):\n",
        "            mask_crop = mask[y:(y+height), x:(x+width)]\n",
        "            train_flooded_mask.append(mask_crop)\n",
        "            x+=width\n",
        "        y+=height\n",
        "train_flooded_mask = np.array(train_flooded_mask)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "KyaHDIIw5M9i"
      },
      "outputs": [],
      "source": [
        "test_img_path = os.getcwd()+ '/drive/MyDrive/Floodnet/test/test-org-img'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "Q7JWCzcF597B"
      },
      "outputs": [],
      "source": [
        "test_images = os.listdir(test_img_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "cRstklD16QL0"
      },
      "outputs": [],
      "source": [
        "test_flooded_images =[]\n",
        "for img_path in test_images:\n",
        "  img = cv2.imread(\"/\".join((test_img_path, img_path)),1)\n",
        "  img = img[0:img_height, 0:img_width,:]\n",
        "  img = cv2.resize(img, resize_dim)\n",
        "  i = 0\n",
        "  j = 0\n",
        "  y = 0\n",
        "\n",
        "  for i in range(h_n):\n",
        "        x=0\n",
        "        for j in range(w_n):\n",
        "            img_crop = img[y:(y+height), x:(x+width), :]\n",
        "            test_flooded_images.append(img_crop)\n",
        "            x+=width\n",
        "        y+=height\n",
        "test_flooded_images = np.array(test_flooded_images)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "qyxxu8B37a5Y"
      },
      "outputs": [],
      "source": [
        "test_mask_path = os.getcwd()+ '/drive/MyDrive/Floodnet/test/test-label-img'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "K5n9ri4T7rIh"
      },
      "outputs": [],
      "source": [
        "test_masks = os.listdir(test_mask_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TFdArAYx72Qd"
      },
      "outputs": [],
      "source": [
        "test_flooded_mask=[]\n",
        "for mask_path in test_masks:\n",
        "  mask = cv2.imread(\"/\".join((test_mask_path, mask_path)),0)\n",
        "  mask = mask[0:img_height, 0:img_width]\n",
        "  mask = cv2.resize(mask, resize_dim)\n",
        "  i = 0\n",
        "  j = 0\n",
        "  y = 0\n",
        "\n",
        "  for i in range(h_n):\n",
        "        x=0\n",
        "        for j in range(w_n):\n",
        "            mask_crop = mask[y:(y+height), x:(x+width)]\n",
        "            test_flooded_mask.append(mask_crop)\n",
        "            x+=width\n",
        "        y+=height\n",
        "test_flooded_mask = np.array(test_flooded_mask)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bstpp5VzNziv"
      },
      "outputs": [],
      "source": [
        "val_img_path = os.getcwd()+'/drive/MyDrive/Floodnet/val/val-org-img'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c6p38WkXO_L2"
      },
      "outputs": [],
      "source": [
        "val_images=  os.listdir(val_img_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K8ZvTjikPF4c"
      },
      "outputs": [],
      "source": [
        "val_flooded_images =[]\n",
        "for img_path in val_images:\n",
        "  img = cv2.imread(\"/\".join((val_img_path, img_path)),1)\n",
        "  img = img[0:img_height, 0:img_width,:]\n",
        "  img = cv2.resize(img, resize_dim)\n",
        "  i = 0\n",
        "  j = 0\n",
        "  y = 0\n",
        "\n",
        "  for i in range(h_n):\n",
        "        x=0\n",
        "        for j in range(w_n):\n",
        "            img_crop = img[y:(y+height), x:(x+width), :]\n",
        "            val_flooded_images.append(img_crop)\n",
        "            x+=width\n",
        "        y+=height\n",
        "val_flooded_images = np.array(val_flooded_images)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yh0X83fPPOAg"
      },
      "outputs": [],
      "source": [
        "val_mask_dir = wd+ \"/drive/MyDrive/Floodnet/val/val-label-img\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dXzs8f35RG-V"
      },
      "outputs": [],
      "source": [
        "val_flooded_mask = []\n",
        "mask_3= os.listdir(val_mask_dir)\n",
        "for mask_path in mask_3:\n",
        "  mask = cv2.imread(\"/\".join((val_mask_dir,mask_path)),0)\n",
        "  mask = mask[0:img_height,0:img_width]\n",
        "  mask = cv2.resize(mask, resize_dim)\n",
        "  i=0\n",
        "  j=0\n",
        "  y=0\n",
        "  for i in range(h_n):\n",
        "    x=0\n",
        "    for j in range(w_n):\n",
        "      mask_crop = mask[y:(y+height),x:(x+width)]\n",
        "      val_flooded_mask.append(mask_crop)\n",
        "      x+=width\n",
        "    y+=height\n",
        "val_flooded_mask = np.array(val_flooded_mask)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ge5Q4rSqRM1U"
      },
      "outputs": [],
      "source": [
        "def prediction(model, image, patch_size):\n",
        "  segm_img = np.zeros(image.shape[:2])\n",
        "  patch_num=1\n",
        "  for i in range(0, image.shape[0],256):\n",
        "    for j in range(0, image.shape[1],256):\n",
        "      single_patch = image[i:i+patch_size, j:j+patch_size]\n",
        "      single_patch_norm = np.expand_dims(normalize(np.array(single_patch),axis=1),2)\n",
        "      single_patch_shape = single_patch_norm.shape[:2]\n",
        "      single_patch_input = np.expand_dims(single_patch_norm,0)\n",
        "      single_patch_prediction = (model.predict(single_patch_input)[0,:,:,0]>0.5).astype(np.uint8)\n",
        "      segm_img[i:i+single_patch_shape[0],j:j+single_patch_shape[1]] += cv2.resize(single_patch_prediction, single_patch_shape[::-1])\n",
        "\n",
        "      print(\"Finished Processing Patch Number\", patch_num, \"At Position\", i,j)\n",
        "\n",
        "      patch_num +=1 \n",
        "\n",
        "      return segm_img"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b_PvZmXkbviE"
      },
      "outputs": [],
      "source": [
        "# print('Trainset Images:',train_flooded_images.shape)\n",
        "# print('Trainset Masks:', train_flooded_mask.shape)\n",
        "# print('Trainset Mask labels:', np.unique(train_flooded_mask))\n",
        "# print('------------------------------------------------')\n",
        "# print('Testset Images:',test_flooded_images.shape)\n",
        "# print('Testset Masks:', test_flooded_mask.shape)\n",
        "# print('Testset Mask labels:', np.unique(test_flooded_mask))\n",
        "# print('------------------------------------------------')\n",
        "# print('Validationset Images:',val_flooded_images.shape)\n",
        "# print('Validationset Masks:', val_flooded_mask.shape)\n",
        "# print('Validationset Mask labels:', np.unique(val_flooded_mask))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dnXyE22RTzBQ"
      },
      "outputs": [],
      "source": [
        "Unet_tuned = load_model('/content/drive/MyDrive/unet_tuned_model.h5')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gbA2fBEVW64y"
      },
      "outputs": [],
      "source": [
        "Unet_untuned = load_model('/content/drive/MyDrive/model_untuned.hdf5')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Qt-bUsi5oABP"
      },
      "outputs": [],
      "source": [
        "pspnet = load_model('/content/drive/MyDrive/psp_model_resnet50.h5')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dCjm416Tar-W"
      },
      "outputs": [],
      "source": [
        "# def evaluate_random_image(model, test_images, test_masks):\n",
        "#     # choose a random test image\n",
        "#     random_index = np.random.choice(len(test_images))\n",
        "#     test_image = test_images[random_index]\n",
        "    \n",
        "#     #predictions on the test image\n",
        "#     test_image = np.expand_dims(test_image, axis=0)\n",
        "#     predictions = model.predict(test_image)\n",
        "    \n",
        "#     #predicted mask\n",
        "#     class_id = predictions.argmax(axis=-1)\n",
        "\n",
        "#     #ground truth \n",
        "#     ground = test_masks[random_index]\n",
        "#     ground = np.squeeze(ground)\n",
        "#     # create a colormap for 10 classes\n",
        "#     cmap = matplotlib.cm.get_cmap('tab10')\n",
        "    \n",
        "#     # display the test image, predicted mask, ground truth\n",
        "#     plt.figure(figsize=(15,8))\n",
        "#     plt.subplot(1,3,1)\n",
        "#     plt.imshow(test_image[0])\n",
        "#     plt.title('Test Image')\n",
        "#     plt.axis('off')\n",
        "\n",
        "#     plt.subplot(1,3,2)\n",
        "#     plt.imshow(ground)\n",
        "#     plt.title('Ground Truth')\n",
        "#     plt.axis('off')\n",
        "\n",
        "#     plt.subplot(1,3,3)\n",
        "#     plt.imshow(class_id[0])\n",
        "#     plt.title('Predicted Mask')\n",
        "#     plt.axis('off')\n",
        "\n",
        "#     # class_labels = ['Building Non-flooded', 'Building Flooded', 'Road Non-Flooded', 'Road', 'Class 5', \n",
        "#     #                 'Tree', 'Class 7', 'Car', 'Pool', 'Background']\n",
        "#     # patches = [mpatches.Patch(color=cmap(i), label=class_labels[i]) for i in range(10)]\n",
        "#     # plt.legend(handles=patches, bbox_to_anchor=(1.05, 1), loc='upper left')\n",
        "    \n",
        "#     plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-3dQ568QnBzO"
      },
      "outputs": [],
      "source": [
        "# evaluate_random_image(Unet_tuned, test_flooded_images, test_flooded_mask)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VA-ZUHSwnyOt"
      },
      "outputs": [],
      "source": [
        "# evaluate_random_image(Unet_untuned, test_flooded_images, test_flooded_mask)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2DE0Bfr-oG3x"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "86Ncg3MJXW12"
      },
      "outputs": [],
      "source": [
        "# ### Applying Trained Models on Large Image \n",
        "# large_image = cv2.imread('/content/drive/MyDrive/Floodnet/train/train-org-img/10687_lab.png',0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GCqH1z-lXugc"
      },
      "outputs": [],
      "source": [
        "# large_image_norm = np.expand_dims(normalize(np.array(large_image),axis=1),2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w-VgO4HjX6dD"
      },
      "outputs": [],
      "source": [
        "# large_image_input = np.expand_dims(large_image_norm, 0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q4Ck9erlYAOV"
      },
      "outputs": [],
      "source": [
        "# segmented_image = prediction(Unet_untuned,large_image,patch_size)\n",
        "\n",
        "# plt.figure(figsize=(10,8)\n",
        "# plt.subplot(1,2,1)\n",
        "# plt.title('Large Image')\n",
        "# plt.imshow(large_image)\n",
        "\n",
        "# plt.subplot(1,2,2)\n",
        "# plt.title('Prediction on Large Image')\n",
        "# plt.imshow(segmented_image)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "machine_shape": "hm",
      "provenance": [],
      "mount_file_id": "1279ivVGcYHdygPwTQI3wthDScBsvJzUF",
      "authorship_tag": "ABX9TyP4R6QS0vtjMgbXMKzvp3/d"
    },
    "gpuClass": "premium",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}